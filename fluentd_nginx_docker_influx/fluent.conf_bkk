<source>
  @type tail
  path /var/log/nginx/access.log
  format nginx
  tag nginx.access.origin
  pos_file /var/log/nginx.log.pos
</source>

<filter nginx.access.origin>
  @type record_transformer
  enable_ruby
  <record>
    "type" "log_file_nginx"
    "data" ${require 'json';require "open-uri";uri = 'http://169.254.169.250/2015-12-19/self/container';html_response = nil ;uuid="uuid_123";env_id = "env_id123";open(uri,"Accept" => "application/json")  do |http| html_response = http.read end;info = JSON.parse(html_response);puts info; uuid=info['uuid'];env_id=info['labels']['io.rancher.project_service.name'];log_info = Hash["log_time" => time.strftime('%Y-%m-%dT%H:%M:%S.%L%:z'), "remote"=>record["remote"],"host"=>record["host"],"user"=>record["user"],"method"=>record["method"],"path"=>record["path"],"code"=>record["code"],"size"=>record["size"],"referer"=>record["referer"],"agent"=>record["agent"]];json_data = Hash["container_uuid"=>uuid,"environment_id"=>env_id, "app_file"=>"access.log","timestamp"=>Time.now.strftime('%Y-%m-%dT%H:%M:%S.%L%:z'), "log_info"=>log_info];json_data.to_json}
  </record>
</filter> 

<filter nginx.access.origin>
  @type record_transformer
  renew_record true
  keep_keys type,data
</filter>
<match nginx.access.origin>
   type burrow
   key_name data
   action inplace
   format json
   tag nginx.access.process
</match>
<match nginx.access.process>
 @type copy
 <store>
  #@type stdout
  @type elasticsearch
  host 223.202.32.60
  port 8056
  logstash_format true
  logstash_prefix fluentd_from_nginx_to_es.log
  flush_interval 5s
  num_threads 2
</store>
<store>
  @type kafka
  brokers 223.202.32.59:8065 
  default_topic fluentd_from_nginx_to_kafka
</store>
</match>
